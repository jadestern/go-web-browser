package main

import (
	"bufio"
	"crypto/tls"
	"encoding/base64"
	"fmt"
	"io"
	"log"
	"net"
	"net/url"
	"os"
	"strconv"
	"strings"
	"sync"
)

// HTTP ê´€ë ¨ ìƒìˆ˜
const (
	HTTPVersion = "HTTP/1.1"
	UserAgent   = "GoWebBrowser/1.0"
)

// HTTP í—¤ë” ì´ë¦„
const (
	HeaderHost       = "Host"
	HeaderConnection = "Connection"
	HeaderUserAgent  = "User-Agent"
)

const MaxConnectionPerHost = 6

var logger *log.Logger

func init() {
	if os.Getenv("PRODUCTION") != "" {
		logger = log.New(io.Discard, "", 0) // Silent by default
	} else {
		logger = log.New(os.Stderr, "[HTTP] ", log.Ltime)
	}
}

// ConnectionPool manages persistent HTTP connections for Keep-Alive.
//
// It maintains a pool of idle connections per server address, allowing
// connection reuse across multiple HTTP requests to the same host.
// This significantly reduces latency by avoiding repeated TCP handshakes.
//
// The pool is thread-safe and can be used concurrently from multiple goroutines.
type ConnectionPool struct {
	connections map[string][]net.Conn // "host:port" â†’ []net.Conn (ë°°ì—´ë¡œ ë³€ê²½!)
	mu          sync.Mutex            // ë™ì‹œì„± ì œì–´ (thread-safe)
	maxPerHost  int                   // ì„œë²„ë‹¹ ìµœëŒ€ ì—°ê²° ìˆ˜
}

// NewConnectionPool creates a new ConnectionPool with default settings.
//
// The pool will maintain up to MaxConnectionsPerHost idle connections
// per server address. Connections exceeding this limit are closed immediately.
func NewConnectionPool() *ConnectionPool {
	return &ConnectionPool{
		connections: make(map[string][]net.Conn),
		maxPerHost:  MaxConnectionPerHost, // HTTP/1.1 ê¶Œì¥ì‚¬í•­: ì„œë²„ë‹¹ ìµœëŒ€ 6ê°œ ì—°ê²°
	}
}

// Get retrieves an idle connection from the pool for the given address.
//
// It returns (conn, true) if an idle connection is available, or (nil, false)
// if the pool is empty for this address. The retrieved connection is removed
// from the pool (check-out pattern) and should be returned with Put after use.
//
// Get is safe for concurrent use.
func (pool *ConnectionPool) Get(address string) (net.Conn, bool) {
	pool.mu.Lock()
	defer pool.mu.Unlock()

	conns := pool.connections[address]
	if len(conns) == 0 {
		// ì‚¬ìš© ê°€ëŠ¥í•œ ì—°ê²° ì—†ìŒ
		return nil, false
	}

	// ë§ˆì§€ë§‰ ì—°ê²° êº¼ë‚´ê¸° (stackì²˜ëŸ¼ LIFO)
	lastIdx := len(conns) - 1
	conn := conns[lastIdx]
	pool.connections[address] = conns[:lastIdx] // ì œê±°

	logger.Printf("â™»ï¸  ê¸°ì¡´ ì—°ê²° ì¬ì‚¬ìš©: %s (ë‚¨ì€ ì—°ê²°: %dê°œ)\n", address, len(conns)-1)
	return conn, true
}

// Put returns a connection to the pool for future reuse.
//
// If the pool already contains maxPerHost connections for this address,
// the connection is closed immediately to prevent resource leaks.
// Otherwise, the connection is stored for reuse by future requests.
//
// Put is safe for concurrent use.
func (pool *ConnectionPool) Put(address string, conn net.Conn) {
	pool.mu.Lock()
	defer pool.mu.Unlock()

	conns := pool.connections[address]

	if len(conns) < pool.maxPerHost {
		// ë°°ì—´ì— ì—¬ìœ  ìˆìœ¼ë©´ ì €ì¥
		pool.connections[address] = append(conns, conn)
		logger.Printf("ğŸ’¾ ì—°ê²° ì €ì¥: %s (ì´ %d/%dê°œ)\n", address, len(conns)+1, pool.maxPerHost)
	} else {
		// Poolì´ ê°€ë“ ì°¨ë©´ ë‹«ê¸° (ëˆ„ìˆ˜ ë°©ì§€!)
		conn.Close()
		logger.Printf("ğŸ”Œ Pool ê°€ë“ ì°¨ì„œ ì—°ê²° ë‹«ê¸°: %s (%d/%d)\n", address, pool.maxPerHost, pool.maxPerHost)
	}
}

// Close closes all idle connections for the given address and removes them from the pool.
//
// This is useful when you want to force new connections on the next request,
// or when shutting down.
//
// Close is safe for concurrent use.
func (pool *ConnectionPool) Close(address string) {
	pool.mu.Lock()
	defer pool.mu.Unlock()

	conns := pool.connections[address]
	for _, conn := range conns {
		conn.Close()
	}
	delete(pool.connections, address)
	logger.Printf("ğŸ”Œ ëª¨ë“  ì—°ê²° ë‹«ê¸°: %s (%dê°œ)\n", address, len(conns))
}

// ì „ì—­ ConnectionPool ì¸ìŠ¤í„´ìŠ¤
var globalConnectionPool = NewConnectionPool()

// Fetcher ì¸í„°í˜ì´ìŠ¤: URLì—ì„œ ì½˜í…ì¸ ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì—­í• ì„ ì¶”ìƒí™”
type Fetcher interface {
	Fetch(u *URL) (string, error)
}

// FileFetcher: file:// ìŠ¤í‚´ì„ ì²˜ë¦¬í•˜ëŠ” Fetcher êµ¬í˜„
type FileFetcher struct{}

// DataFetcher: data:// ìŠ¤í‚´ì„ ì²˜ë¦¬í•˜ëŠ” Fetcher êµ¬í˜„
type DataFetcher struct{}

// HTTPFetcher: http://, https:// ìŠ¤í‚´ì„ ì²˜ë¦¬í•˜ëŠ” Fetcher êµ¬í˜„
type HTTPFetcher struct{}

// ViewSourceFetcher: view-source:// ìŠ¤í‚´ì„ ì²˜ë¦¬í•˜ëŠ” Fetcher êµ¬í˜„
type ViewSourceFetcher struct{}

// fetcherRegistry: schemeì— ë”°ë¥¸ Fetcherë¥¼ ë“±ë¡í•˜ëŠ” ë ˆì§€ìŠ¤íŠ¸ë¦¬
var fetcherRegistry = map[Scheme]Fetcher{
	SchemeFile:       &FileFetcher{},
	SchemeData:       &DataFetcher{},
	SchemeHTTP:       &HTTPFetcher{},
	SchemeHTTPS:      &HTTPFetcher{},
	SchemeViewSource: &ViewSourceFetcher{},
}

// Request: URLì—ì„œ ì½˜í…ì¸ ë¥¼ ê°€ì ¸ì˜¤ëŠ” ë©”ì„œë“œ
func (u *URL) Request() (string, error) {
	fetcher, ok := fetcherRegistry[u.Scheme]
	if !ok {
		return "", fmt.Errorf("ì§€ì›í•˜ì§€ ì•ŠëŠ” í”„ë¡œí† ì½œ: %s", u.Scheme)
	}
	return fetcher.Fetch(u)
}

// Fetch: FileFetcherì˜ Fetch ë©”ì„œë“œ êµ¬í˜„
func (f *FileFetcher) Fetch(u *URL) (string, error) {
	filePath := u.Path

	// Windows ì ˆëŒ€ ê²½ë¡œ ì²˜ë¦¬: /C:/path â†’ C:/path
	if len(filePath) > 2 && filePath[0] == '/' && filePath[2] == ':' {
		filePath = filePath[1:]
	}

	content, err := os.ReadFile(filePath)
	if err != nil {
		return "", fmt.Errorf("íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: %v", err)
	}

	logger.Printf("--- íŒŒì¼ %s ì½ê¸° ì™„ë£Œ ---\n", filePath)
	return string(content), nil
}

// Fetch: DataFetcherì˜ Fetch ë©”ì„œë“œ êµ¬í˜„
func (d *DataFetcher) Fetch(u *URL) (string, error) {
	dataStr := u.Path

	commaIdx := strings.Index(dataStr, ",")
	if commaIdx == -1 {
		return "", fmt.Errorf("data ìŠ¤í‚´ í˜•ì‹ì´ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤ (ì‰¼í‘œ ì—†ìŒ)")
	}

	metadata := dataStr[:commaIdx]
	data := dataStr[commaIdx+1:]

	if strings.Contains(metadata, ";base64") {
		decoded, err := base64.StdEncoding.DecodeString(data)
		if err != nil {
			return "", fmt.Errorf("base64 ë””ì½”ë”© ì‹¤íŒ¨: %v", err)
		}
		data = string(decoded)
		logger.Printf("--- [data] base64 ë””ì½”ë”© ì™„ë£Œ ---\n")
	} else {
		decoded, err := url.QueryUnescape(data)
		if err != nil {
			decoded = data
		}
		data = decoded
		logger.Println("--- [data] URL íŒŒì‹± ì™„ë£Œ ---")
	}

	return data, nil
}

// Fetch: HTTPFetcherì˜ Fetch ë©”ì„œë“œ êµ¬í˜„
func (h *HTTPFetcher) Fetch(u *URL) (string, error) {
	const maxRedirects = 10
	currentURL := u

	for i := 0; i < maxRedirects; i++ {
		statusCode, body, headers, err := h.doRequest(currentURL)
		if err != nil {
			return "", err
		}

		if statusCode < 300 || statusCode >= 400 {
			return body, nil
		}

		location := headers["location"]
		if location == "" {
			return "", fmt.Errorf("ë¦¬ë‹¤ì´ë ‰íŠ¸ ì‘ë‹µì— Location í—¤ë”ê°€ ì—†ìŠµë‹ˆë‹¤ (status %d)", statusCode)
		}

		logger.Printf("ë¦¬ë‹¤ì´ë ‰íŠ¸ %d: %d -> %s", i+1, statusCode, location)

		nextURL, err := resolveURL(currentURL, location)
		if err != nil {
			return "", fmt.Errorf("ë¦¬ë‹¤ì´ë ‰íŠ¸ URL ë³€í™˜ ì‹¤íŒ¨ %q: %w", location, err)
		}

		currentURL = nextURL
	}

	return "", fmt.Errorf("ìµœëŒ€ ë¦¬ë‹¤ì´ë ‰íŠ¸ íšŸìˆ˜ ì´ˆê³¼ (ìµœëŒ€ %díšŒ)", maxRedirects)
}

// resolveURL resolves a potentially relative URL against a base URL.
//
// If location is an absolute URL (starts with http:// or https://), it is parsed directly.
// If location is a relative URL (starts with /), it uses the base URL's scheme and host.
//
// Examples:
//   - resolveURL("http://example.com/page", "https://other.com/new") -> "https://other.com/new"
//   - resolveURL("http://example.com/page", "/new") -> "http://example.com/new"
func resolveURL(base *URL, location string) (*URL, error) {
	if strings.HasPrefix(location, "http://") || strings.HasPrefix(location, "https://") {
		return NewURL(location)
	}

	if strings.HasPrefix(location, "/") {
		var absoluteURL string
		if base.Scheme == SchemeHTTPS && base.Port == DefaultHTTPSPort {
			absoluteURL = fmt.Sprintf("https://%s%s", base.Host, location)
		} else if base.Scheme == SchemeHTTP && base.Port == DefaultHTTPPort {
			absoluteURL = fmt.Sprintf("http://%s%s", base.Host, location)
		} else {
			absoluteURL = fmt.Sprintf("%s://%s:%d%s", base.Scheme, base.Host, base.Port, location)
		}
		return NewURL(absoluteURL)
	}

	return nil, fmt.Errorf("ì§€ì›í•˜ì§€ ì•ŠëŠ” Location í˜•ì‹: %q (ì ˆëŒ€ URL ë˜ëŠ” ìƒëŒ€ ê²½ë¡œê°€ ì•„ë‹˜)", location)
}

// doRequest performs a single HTTP request and returns status code, body, headers
func (h *HTTPFetcher) doRequest(u *URL) (int, string, map[string]string, error) {
	address := fmt.Sprintf("%s:%d", u.Host, u.Port)

	// 1. ConnectionPoolì—ì„œ ê¸°ì¡´ ì—°ê²° ì°¾ê¸°
	conn, found := globalConnectionPool.Get(address)

	if !found {
		// 2. Poolì— ì—†ìœ¼ë©´ ìƒˆë¡œìš´ ì—°ê²° ìƒì„±
		logger.Printf("ğŸ†• ìƒˆ ì—°ê²° ìƒì„±: %s\n", address)
		var err error

		if u.Scheme == SchemeHTTPS {
			conn, err = tls.Dial("tcp", address, nil)
		} else {
			conn, err = net.Dial("tcp", address)
		}

		if err != nil {
			return 0, "", nil, err
		}
	}
	// (found == trueì¸ ê²½ìš°ëŠ” Get()ì—ì„œ "â™»ï¸ ê¸°ì¡´ ì—°ê²° ì¬ì‚¬ìš©" ë©”ì‹œì§€ ì¶œë ¥í•¨)

	// HTTP ìš”ì²­ ë©”ì‹œì§€ ë§Œë“¤ê¸°
	headers := map[string]string{
		HeaderHost: u.Host,
		// Connection: close í—¤ë” ì œê±°!
		// â†’ HTTP/1.1ì˜ ê¸°ë³¸ ë™ì‘ì´ keep-aliveì´ë¯€ë¡œ ìƒëµ
		HeaderUserAgent: UserAgent,
	}

	requestLine := fmt.Sprintf("GET %s %s\r\n", u.Path, HTTPVersion)

	var headerLines strings.Builder
	headerLines.WriteString(requestLine)
	for key, value := range headers {
		headerLines.WriteString(fmt.Sprintf("%s: %s\r\n", key, value))
	}

	headerLines.WriteString("\r\n")

	request := headerLines.String()

	// ì„œë²„ì— ë©”ì‹œì§€ ë³´ë‚´ê¸°
	_, err := conn.Write([]byte(request))
	if err != nil {
		conn.Close() // ì „ì†¡ ì‹¤íŒ¨ ì‹œ ì—°ê²° ë‹«ê¸°
		return 0, "", nil, err
	}

	// ì„œë²„ì˜ ëŒ€ë‹µ(ì‘ë‹µ) ì½ê¸°
	logger.Printf("--- [%s:%d] ì—°ê²° ë° ìš”ì²­ ì™„ë£Œ ---\n", u.Host, u.Port)

	statusCode, body, responseHeader, err := parseResponse(conn)
	if err != nil {
		conn.Close() // ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì—°ê²° ë‹«ê¸°
		return 0, "", nil, err
	}

	// 3. ì„±ê³µí•˜ë©´ Poolì— ì—°ê²° ì €ì¥ (ì¬ì‚¬ìš©ì„ ìœ„í•´)
	globalConnectionPool.Put(address, conn)

	return statusCode, body, responseHeader, nil
}

// readChunkedBody reads an HTTP response body with Transfer-Encoding: chunked.
//
// Chunked encoding format:
//
//	<hex-size>\r\n
//	<data>\r\n
//	<hex-size>\r\n
//	<data>\r\n
//	0\r\n
//	\r\n
//
// Example:
//
//	5\r\n
//	Hello\r\n
//	6\r\n
//	 World\r\n
//	0\r\n
//	\r\n
//
// â†’ "Hello World"
//
// Returns:
//   - body bytes
//   - error if chunk parsing fails
func readChunkedBody(reader *bufio.Reader) ([]byte, error) {
	var body []byte

	for {
		// 1. Read chunk size line (hex number + \r\n)
		sizeLine, err := reader.ReadString('\n')
		if err != nil {
			return nil, fmt.Errorf("failed to read chunk size: %w", err)
		}

		// 2. Parse hex size to decimal
		sizeLine = strings.TrimSpace(sizeLine)
		chunkSize, err := strconv.ParseInt(sizeLine, 16, 64)
		if err != nil {
			return nil, fmt.Errorf("invalid chunk size %q: %w", sizeLine, err)
		}

		logger.Printf("Read chunk size: %d (0x%s)", chunkSize, sizeLine)

		// 3. If chunk size is 0, we're done
		if chunkSize == 0 {
			reader.ReadString('\n')
			break
		}

		// 4. Read chunk data (exactly chunkSize bytes)
		chunkData := make([]byte, chunkSize)
		_, err = io.ReadFull(reader, chunkData)
		if err != nil {
			return nil, fmt.Errorf("failed to read chunk data: %w", err)
		}

		// 5. Read trailing \r\n after chunk data
		_, err = reader.ReadString('\n')
		if err != nil {
			return nil, fmt.Errorf("failed to read chunk trailing CRLF: %w", err)
		}

		// 6. Append to body
		body = append(body, chunkData...)
	}
	return body, nil
}

// readHeaders reads HTTP response headers from reader.
//
// It reads lines until it encounters an empty line (\r\n or \n),
// which signals the end of headers. Each header is parsed as "Key: Value"
// and stored in a map.
//
// Returns:
//   - headers: map of header names to values
//   - error: if header reading fails
func readHeaders(reader *bufio.Reader) (map[string]string, error) {
	headers := make(map[string]string)

	for {
		line, err := reader.ReadString('\n')
		if err != nil {
			if err == io.EOF {
				break
			}
			return nil, fmt.Errorf("í—¤ë” ì½ê¸° ì‹¤íŒ¨: %w", err)
		}

		// ë¹ˆ ì¤„ì´ ë‚˜ì˜¤ë©´ í—¤ë” ë
		if line == "\r\n" || line == "\n" {
			break
		}

		// í—¤ë” íŒŒì‹±: "Content-Length: 1234\r\n" â†’ key: "Content-Length", value: "1234"
		line = strings.TrimSpace(line) // ì•ë’¤ ê³µë°± ì œê±°
		colonIdx := strings.Index(line, ":")
		if colonIdx > 0 {
			key := strings.TrimSpace(line[:colonIdx])     // "Content-Length"
			value := strings.TrimSpace(line[colonIdx+1:]) // "1234"
			// Normalize header names to lowercase (HTTP headers are case-insensitive)
			headers[strings.ToLower(key)] = value
		}
	}

	// ë””ë²„ê¹…: ì„œë²„ê°€ keep-aliveë¡œ ì‘ë‹µí–ˆëŠ”ì§€ í™•ì¸
	if connHeader, ok := headers["connection"]; ok {
		logger.Printf("ğŸ”Œ ì„œë²„ ì‘ë‹µ Connection í—¤ë”: %s\n", connHeader)
	} else {
		fmt.Println("ğŸ”Œ Connection í—¤ë” ì—†ìŒ (HTTP/1.1 ê¸°ë³¸ = keep-alive)")
	}

	logger.Println("=== All Response Headers ===")
	for key, value := range headers {
		logger.Printf("%s: %s", key, value)
	}
	logger.Println("=========================")

	return headers, nil
}

// readBody reads HTTP response body based on headers.
//
// It uses different strategies depending on the headers:
//  1. If Transfer-Encoding: chunked â†’ read chunked body
//  2. If Content-Length present â†’ read exact bytes
//  3. Otherwise, â†’ read until EOF
//
// Strategies 1 and 2 allow connection reuse (Keep-Alive).
// Strategy 3 closes the connection.
//
// Returns:
//   - body bytes
//   - error: if body reading fails
func readBody(reader *bufio.Reader, headers map[string]string) ([]byte, error) {
	if transferEncoding, ok := headers["transfer-Encoding"]; ok && transferEncoding == "chunked" {
		bodyBytes, err := readChunkedBody(reader)
		if err != nil {
			return nil, fmt.Errorf("failed to read chunked body: %w", err)
		}
		logger.Println("Read chunked body, connection reusable")
		return bodyBytes, nil
	} else if contentLengthStr, ok := headers["content-Length"]; ok {
		// Content-Lengthê°€ ìˆìœ¼ë©´: ì •í™•íˆ ê·¸ë§Œí¼ë§Œ ì½ê¸°
		logger.Printf("ğŸ“ Content-Length í—¤ë” ë°œê²¬: %s ë°”ì´íŠ¸\n", contentLengthStr)

		// string â†’ int ë³€í™˜ (ì˜ˆ: "1234" â†’ 1234)
		contentLength, parseErr := strconv.Atoi(contentLengthStr)
		if parseErr != nil || contentLength < 0 {
			return nil, fmt.Errorf("Content-Length íŒŒì‹± ì‹¤íŒ¨: %v", parseErr)
		}

		// ì •í™•íˆ contentLength ë°”ì´íŠ¸ë§Œ ì½ê¸°
		bodyBytes := make([]byte, contentLength) // Në°”ì´íŠ¸ ë²„í¼ ìƒì„±
		_, err := io.ReadFull(reader, bodyBytes) // ì •í™•íˆ Në°”ì´íŠ¸ ì½ê¸°
		if err != nil {
			return nil, fmt.Errorf("ë°”ë”” ì½ê¸° ì‹¤íŒ¨ (Content-Length: %d): %w", contentLength, err)
		}

		logger.Printf("âœ… %d ë°”ì´íŠ¸ ì •í™•íˆ ì½ìŒ (ì†Œì¼“ ìœ ì§€ ê°€ëŠ¥!)\n", contentLength)
		return bodyBytes, nil
	}

	// Content-Lengthê°€ ì—†ìœ¼ë©´: ê¸°ì¡´ ë°©ì‹ (io.ReadAll)
	logger.Println("âš ï¸  Content-Length ì—†ìŒ, ì—°ê²° ëê¹Œì§€ ì½ê¸°")
	bodyBytes, err := io.ReadAll(reader)
	if err != nil && err != io.EOF {
		return nil, fmt.Errorf("ë°”ë”” ì½ê¸° ì‹¤íŒ¨: %w", err)
	}

	return bodyBytes, nil
}

// parseResponse parses an HTTP response and returns the status code, body and headers.
//
// It reads the status line, parses headers, and reads the body.
// This function orchestrates the parsing process by delegating to:
//   - readHeaders() for header parsing
//   - readBody() for body reading with appropriate strategy
//
// Returns:
//   - statusCode: HTTP status code (e.g., 200, 302, 404)
//   - body: response body as string
//   - headers: map of header names to values
//   - error: any error encountered during parsing
func parseResponse(r io.Reader) (statusCode int, body string, headers map[string]string, err error) {
	reader := bufio.NewReader(r)

	// 1. Status Line ì½ê¸° (ì˜ˆ: HTTP/1.1 200 OK)
	statusLine, err := reader.ReadString('\n')
	if err != nil {
		return 0, "", nil, fmt.Errorf("ìƒíƒœ ë¼ì¸ ì½ê¸° ì‹¤íŒ¨: %w", err)
	}
	_ = statusLine // í˜„ì¬ëŠ” ìƒíƒœ ì½”ë“œë¥¼ ê²€ì‚¬í•˜ì§€ ì•Šì§€ë§Œ, ë‚˜ì¤‘ì— í™•ì¥ì„ ìœ„í•´ ì €ì¥

	statusLine = strings.TrimSpace(statusLine)
	parts := strings.SplitN(statusLine, " ", 3)
	if len(parts) < 2 {
		return 0, "", nil, fmt.Errorf("invalid status line: %q", statusLine)
	}

	statusCode, err = strconv.Atoi(parts[1])
	if err != nil {
		return 0, "", nil, fmt.Errorf("invalid status code in status line %q: %w", statusLine, err)
	}

	logger.Printf("Status: %d %s", statusCode, statusLine)

	headers, err = readHeaders(reader)
	if err != nil {
		return statusCode, "", nil, err
	}

	// 3. Body ì½ê¸°: Content-Lengthì— ë”°ë¼ ë‹¤ë¥´ê²Œ ì²˜ë¦¬
	bodyBytes, err := readBody(reader, headers)
	if err != nil {
		return statusCode, "", headers, err
	}

	return statusCode, string(bodyBytes), headers, nil
}

// Fetch: ViewSourceFetcherì˜ Fetch ë©”ì„œë“œ êµ¬í˜„
func (v *ViewSourceFetcher) Fetch(u *URL) (string, error) {
	// Pathì—ëŠ” ë‚´ë¶€ URL ì „ì²´ê°€ ë“¤ì–´ìˆìŒ (ì˜ˆ: "http://example.org/")
	innerURLStr := u.Path

	if innerURLStr == "" {
		return "", fmt.Errorf("view-source: ë‚´ë¶€ URLì´ ì—†ìŠµë‹ˆë‹¤")
	}

	// ë‚´ë¶€ URL íŒŒì‹±
	innerURL, err := NewURL(innerURLStr)
	if err != nil {
		return "", fmt.Errorf("view-source: ë‚´ë¶€ URL íŒŒì‹± ì‹¤íŒ¨: %v", err)
	}

	// ë‚´ë¶€ URLë¡œ ì½˜í…ì¸  ê°€ì ¸ì˜¤ê¸° (ì›ë³¸ ê·¸ëŒ€ë¡œ ë°˜í™˜)
	content, err := innerURL.Request()
	if err != nil {
		return "", fmt.Errorf("view-source: ë‚´ë¶€ URL ìš”ì²­ ì‹¤íŒ¨: %v", err)
	}

	logger.Println("--- [view-source] ì›ë³¸ ì†ŒìŠ¤ ë°˜í™˜ ---")
	return content, nil
}
